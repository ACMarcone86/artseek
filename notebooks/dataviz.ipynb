{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llavart.utils.dirutils import get_data_dir\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33734529_0.jpg</td>\n",
       "      <td>Architecture is the process and the product of...</td>\n",
       "      <td>0.260930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33734529_1.jpg</td>\n",
       "      <td>Paintings of human figures can be found in the...</td>\n",
       "      <td>0.296242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33734529_2.jpg</td>\n",
       "      <td>Drawing and painting go back tens of thousands...</td>\n",
       "      <td>0.335946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33734529_3.jpg</td>\n",
       "      <td>The 17th century witnessed the emergence of th...</td>\n",
       "      <td>0.289089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33734529_4.jpg</td>\n",
       "      <td>Towards the end of the 19th century, several y...</td>\n",
       "      <td>0.298388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506064</th>\n",
       "      <td>25646039_0.jpg</td>\n",
       "      <td>The Boston Journal of Natural History (1834-18...</td>\n",
       "      <td>0.327892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506065</th>\n",
       "      <td>1494135_0.jpg</td>\n",
       "      <td>In 1903, under the direction of Ben E. Rich, t...</td>\n",
       "      <td>0.373264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506066</th>\n",
       "      <td>1494135_1.jpg</td>\n",
       "      <td>In June 1907, the Elders' Journal was merged w...</td>\n",
       "      <td>0.355782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506067</th>\n",
       "      <td>12281645_1.jpg</td>\n",
       "      <td>Botaniska Notiser was a Swedish scientific per...</td>\n",
       "      <td>0.261090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506068</th>\n",
       "      <td>24264840_0.jpg</td>\n",
       "      <td>The Proceedings of the Academy of Natural Scie...</td>\n",
       "      <td>0.332359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506069 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                          paragraph  \\\n",
       "0       33734529_0.jpg  Architecture is the process and the product of...   \n",
       "1       33734529_1.jpg  Paintings of human figures can be found in the...   \n",
       "2       33734529_2.jpg  Drawing and painting go back tens of thousands...   \n",
       "3       33734529_3.jpg  The 17th century witnessed the emergence of th...   \n",
       "4       33734529_4.jpg  Towards the end of the 19th century, several y...   \n",
       "...                ...                                                ...   \n",
       "506064  25646039_0.jpg  The Boston Journal of Natural History (1834-18...   \n",
       "506065   1494135_0.jpg  In 1903, under the direction of Ben E. Rich, t...   \n",
       "506066   1494135_1.jpg  In June 1907, the Elders' Journal was merged w...   \n",
       "506067  12281645_1.jpg  Botaniska Notiser was a Swedish scientific per...   \n",
       "506068  24264840_0.jpg  The Proceedings of the Academy of Natural Scie...   \n",
       "\n",
       "        similarity  \n",
       "0         0.260930  \n",
       "1         0.296242  \n",
       "2         0.335946  \n",
       "3         0.289089  \n",
       "4         0.298388  \n",
       "...            ...  \n",
       "506064    0.327892  \n",
       "506065    0.373264  \n",
       "506066    0.355782  \n",
       "506067    0.261090  \n",
       "506068    0.332359  \n",
       "\n",
       "[506069 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(get_data_dir() / \"texts\" / \"wiki_img_paragraph336_clean.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicola/miniconda3/envs/llavart/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://cc6772ae7b7845aa15.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cc6772ae7b7845aa15.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "df_filtered = df\n",
    "last_query = \"\"\n",
    "slider = gr.Slider(maximum=len(df_filtered), step=1, interactive=True)\n",
    "\n",
    "def show_sample(slider):\n",
    "    row = df_filtered.iloc[slider]\n",
    "    image = Image.open(get_data_dir() / \"wikipedia_images336\" / row[\"file_name\"])\n",
    "    return image, row[\"paragraph\"] + f\"\\n\\nSimilarity: {row['similarity']:.2f}\"\n",
    "\n",
    "def make_query(query):\n",
    "    global df_filtered\n",
    "    df_filtered = df[df[\"paragraph\"].str.contains(query)]\n",
    "\n",
    "    if len(df_filtered) == 0:\n",
    "        df_filtered = df\n",
    "\n",
    "    df_filtered = df_filtered.reset_index(drop=True)\n",
    "    slider = gr.Slider(maximum=len(df_filtered) - 1, value=0, step=1)\n",
    "    image, paragraph = show_sample(0)\n",
    "    return slider, image, paragraph\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # The Wiki Visual Arts Image-Paragraph Dataset\n",
    "    This is a dataset of images and paragraphs from Wikipedia articles on visual arts. The dataset\n",
    "    can be used to train models for vision-language tasks such as **retrieval** and **captioning**.\n",
    "\n",
    "    ## Demo Instructions\n",
    "    Use the slider to select an example. Write a query to filter examples where the paragraph contains the query.\n",
    "    \"\"\")\n",
    "    image, paragraph = show_sample(0)\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            slider = gr.Slider(maximum=len(df_filtered) - 1, step=1)\n",
    "            query = gr.Textbox(lines=1, label=\"Search query\")\n",
    "        with gr.Column():\n",
    "            image = gr.Image(label=\"Image\", height=400, width=400, value=image)\n",
    "            paragraph = gr.Textbox(lines=5, label=\"Paragraph\", value=paragraph)\n",
    "    query.change(fn=make_query, inputs=[query], outputs=[slider, image, paragraph])\n",
    "    slider.change(fn=show_sample, inputs=[slider], outputs=[image, paragraph])\n",
    "\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    ## Pages Collection\n",
    "    The dataset was collected by scraping Wikipedia articles on visual arts. Specifically,\n",
    "    we collect all pages connected to the Wikipedia Category **Visual Arts** and, recursively,\n",
    "    to all subcategories of **Visual Arts** and their subcategories up to a depth of 5.\n",
    "\n",
    "    The collected pages amounted to a total of more than 500,000 pages.\n",
    "\n",
    "    ## Image-Paragraph Pairs\n",
    "    From the collected pages, we extracted image-paragraph pairs. We extract all images and paragraphs\n",
    "    in a page and then match each image to the paragraph that is most similar to it. We use the\n",
    "    cosine similarity between the image and paragraph CLIP embeddings to match them. The collected\n",
    "    pairs were more than 2,000,000 pairs.\n",
    "\n",
    "    ## Data Cleaning\n",
    "    We clean the dataset by removing image-paragraph pairs that are not relevant to visual arts.\n",
    "\n",
    "    Firstly, we match images against the following prompts to remove bad examples:\n",
    "\n",
    "    - *A low-quality icon*\n",
    "    - *A low-quality object*\n",
    "    - *A broken image*\n",
    "    - *A single color image*\n",
    "    - *A badly cut-out icon*\n",
    "    - *A gray image with a black square*\n",
    "    - *A white image with black bands*\n",
    "    - *An icon of a country flag*\n",
    "\n",
    "    We then remove pairs where the image matches one of the prompts with a cosine similarity higher than 0.25.\n",
    "\n",
    "    Then, we remove image-paragraphs containg photos that are not related to the visual arts,\n",
    "    by defining the following list of prompts:\n",
    "\n",
    "    - *A photo*\n",
    "    - *An artistic photo*\n",
    "    - *A painting*\n",
    "    - *A sculpture*\n",
    "    - *A print*\n",
    "    - *A comic*\n",
    "    - *An architecture*\n",
    "    - *A design*\n",
    "    - *A handicraft*\n",
    "    - *A drawing*\n",
    "    - *An illustration*\n",
    "    - *A ceramic*\n",
    "\n",
    "    We remove pairs where the image matches the prompt *A photo* with a cosine similarity higher than that obtained for tha other prompts.\n",
    "    \"\"\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vitart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
